<?xml version="1.0" encoding="UTF-8"?><rss version="2.0"
	xmlns:content="http://purl.org/rss/1.0/modules/content/"
	xmlns:dc="http://purl.org/dc/elements/1.1/"
	xmlns:atom="http://www.w3.org/2005/Atom"
	xmlns:sy="http://purl.org/rss/1.0/modules/syndication/"
	xmlns:itunes="http://www.itunes.com/dtds/podcast-1.0.dtd"
xmlns:rawvoice="http://www.rawvoice.com/rawvoiceRssModule/"

	>
<channel>
	<title>Comments on: The Blindness of Scientists: The Problem isn&#8217;t False Positives, It&#8217;s Undetected Positives</title>
	<atom:link href="http://blog.sethroberts.net/2013/09/10/the-blindness-of-scientists-the-real-problem-is-undetected-positives/feed/" rel="self" type="application/rss+xml" />
	<link>http://blog.sethroberts.net/2013/09/10/the-blindness-of-scientists-the-real-problem-is-undetected-positives/</link>
	<description>Personal Science, Self-Experimentation, Scientific Method</description>
	<lastBuildDate>Wed, 17 Sep 2014 20:18:18 +0000</lastBuildDate>
		<sy:updatePeriod>hourly</sy:updatePeriod>
		<sy:updateFrequency>1</sy:updateFrequency>
	<generator>http://wordpress.org/?v=3.7.1</generator>
	<item>
		<title>By: Wil B</title>
		<link>http://blog.sethroberts.net/2013/09/10/the-blindness-of-scientists-the-real-problem-is-undetected-positives/#comment-1139868</link>
		<dc:creator><![CDATA[Wil B]]></dc:creator>
		<pubDate>Thu, 12 Sep 2013 15:31:28 +0000</pubDate>
		<guid isPermaLink="false">http://blog.sethroberts.net/?p=11096#comment-1139868</guid>
		<description><![CDATA[Seth said (re the scientific approach of attempting to disprove a hypothesis vs. trying to prove the hypothesis):  You don’t have a choice. You can’t choose whether your test will support or falsify your theory. That depends on the results. 

Perhaps we are discussing different categories and goals of &quot;testing.&quot;  Staying with the category of drug development and testing for purposes of illustration, let&#039;s say a company&#039;s hypothesis is that compound X, being developed in a laboratory, is generally effective to treat Y disease in humans and will not have any bad side effects.   Employing the usual testing methods, a study group of investigators administers  compound X to human subjects with disease Y to see if the compound cures (or ameliorates) the disease.  If a significant number of the subjects are cured (or get better) after taking the compound, and do not appear to suffer debilitating side effects, the hypothesis is &quot;proven,&quot; the results are positive, and the company will make a lot of money selling it to patients with disease Y. 
 
But can we be certain that the testing and record keeping was conducted honestly and without bias in advance; i.e., free of undue influence and a strong desire to reach a certain result?  Wouldn&#039;t it be better to at least have a separate, independent arm of the study (if for no other reason than to keep the results-oriented group of investigators honest) examining and tracking the same test subjects and maintaining their own data with the opposite &quot;goal&quot; of falsifying the first group&#039;s finding? 
 
If the latter group fails in its effort to falsify the first group&#039;s results, that&#039;s fine because the company (and the FDA) could have much more confidence that the compound will, in fact, be a safe and efficacious product.  In this instance the failure to falsify was in reality a positive result!
  
In this context, which method of drug development, testing (and perhaps ultimate approval) would most doctors and end users prefer?

Wil B.]]></description>
		<content:encoded><![CDATA[<p>Seth said (re the scientific approach of attempting to disprove a hypothesis vs. trying to prove the hypothesis):  You don’t have a choice. You can’t choose whether your test will support or falsify your theory. That depends on the results. </p>
<p>Perhaps we are discussing different categories and goals of &#8220;testing.&#8221;  Staying with the category of drug development and testing for purposes of illustration, let&#8217;s say a company&#8217;s hypothesis is that compound X, being developed in a laboratory, is generally effective to treat Y disease in humans and will not have any bad side effects.   Employing the usual testing methods, a study group of investigators administers  compound X to human subjects with disease Y to see if the compound cures (or ameliorates) the disease.  If a significant number of the subjects are cured (or get better) after taking the compound, and do not appear to suffer debilitating side effects, the hypothesis is &#8220;proven,&#8221; the results are positive, and the company will make a lot of money selling it to patients with disease Y. </p>
<p>But can we be certain that the testing and record keeping was conducted honestly and without bias in advance; i.e., free of undue influence and a strong desire to reach a certain result?  Wouldn&#8217;t it be better to at least have a separate, independent arm of the study (if for no other reason than to keep the results-oriented group of investigators honest) examining and tracking the same test subjects and maintaining their own data with the opposite &#8220;goal&#8221; of falsifying the first group&#8217;s finding? </p>
<p>If the latter group fails in its effort to falsify the first group&#8217;s results, that&#8217;s fine because the company (and the FDA) could have much more confidence that the compound will, in fact, be a safe and efficacious product.  In this instance the failure to falsify was in reality a positive result!</p>
<p>In this context, which method of drug development, testing (and perhaps ultimate approval) would most doctors and end users prefer?</p>
<p>Wil B.</p>
]]></content:encoded>
	</item>
	<item>
		<title>By: August</title>
		<link>http://blog.sethroberts.net/2013/09/10/the-blindness-of-scientists-the-real-problem-is-undetected-positives/#comment-1139605</link>
		<dc:creator><![CDATA[August]]></dc:creator>
		<pubDate>Wed, 11 Sep 2013 16:30:24 +0000</pubDate>
		<guid isPermaLink="false">http://blog.sethroberts.net/?p=11096#comment-1139605</guid>
		<description><![CDATA[I agree, but they are &#039;testing&#039; against computer models and presenting the results as evidence to the public.  I&#039;ve even heard of it locally, in biochem. My coworker&#039;s former boss was doing research into proteins related to cancer.  They kept trying to get him to test against computer models.  They closed his lab down eventually, and he had to go work as someone else&#039;s assistant.]]></description>
		<content:encoded><![CDATA[<p>I agree, but they are &#8216;testing&#8217; against computer models and presenting the results as evidence to the public.  I&#8217;ve even heard of it locally, in biochem. My coworker&#8217;s former boss was doing research into proteins related to cancer.  They kept trying to get him to test against computer models.  They closed his lab down eventually, and he had to go work as someone else&#8217;s assistant.</p>
]]></content:encoded>
	</item>
	<item>
		<title>By: Kim Øyhus, physicist</title>
		<link>http://blog.sethroberts.net/2013/09/10/the-blindness-of-scientists-the-real-problem-is-undetected-positives/#comment-1139473</link>
		<dc:creator><![CDATA[Kim Øyhus, physicist]]></dc:creator>
		<pubDate>Wed, 11 Sep 2013 06:38:20 +0000</pubDate>
		<guid isPermaLink="false">http://blog.sethroberts.net/?p=11096#comment-1139473</guid>
		<description><![CDATA[Tests confirming a theory, will give less and less confirmation for more and more work.
Tests falsifying a theory, are much more efficient.

This means that cheap good scientific results will consist of lots of partially confirmed theories, with lots more falsified theories discarded.

&lt;strong&gt;Seth: &quot;Tests falsifying a theory are much more efficient.&quot; Hmm. You don&#039;t have a choice. You can&#039;t choose whether your test will support or falsify your theory. That depends on the results. However, I do think that tests of ideas of intermediate plausibility produce more information -- more shift in belief -- than tests of ideas that are very high or very low in plausibility. But that&#039;s just the average shift in belief. More interesting is what the distributions look like.&lt;/strong&gt;]]></description>
		<content:encoded><![CDATA[<p>Tests confirming a theory, will give less and less confirmation for more and more work.<br />
Tests falsifying a theory, are much more efficient.</p>
<p>This means that cheap good scientific results will consist of lots of partially confirmed theories, with lots more falsified theories discarded.</p>
<p><strong>Seth: &#8220;Tests falsifying a theory are much more efficient.&#8221; Hmm. You don&#8217;t have a choice. You can&#8217;t choose whether your test will support or falsify your theory. That depends on the results. However, I do think that tests of ideas of intermediate plausibility produce more information &#8212; more shift in belief &#8212; than tests of ideas that are very high or very low in plausibility. But that&#8217;s just the average shift in belief. More interesting is what the distributions look like.</strong></p>
]]></content:encoded>
	</item>
	<item>
		<title>By: Wil B</title>
		<link>http://blog.sethroberts.net/2013/09/10/the-blindness-of-scientists-the-real-problem-is-undetected-positives/#comment-1139326</link>
		<dc:creator><![CDATA[Wil B]]></dc:creator>
		<pubDate>Tue, 10 Sep 2013 16:13:37 +0000</pubDate>
		<guid isPermaLink="false">http://blog.sethroberts.net/?p=11096#comment-1139326</guid>
		<description><![CDATA[Experience has shown, I believe, that this is a particularly glaring problem in the context of drug testing and development in the pharmaceutical industry.  Much of this is surely brought about by conflicts of interest (and a certain amount of corruption) which are endemic in this exceedingly profit-driven industry.  

Another issue is the common disregard of true scientific method (Popper anyone?) in the planning and conduct of testing because so much of the &quot;testing&quot; is done with profits in mind.  Shouldn&#039;t the object (protocol) for whatever is being tested be to disprove a particular hypothesis, rather than allowing biases to creep in so that a certain desired result can be realized and money can be made?  A failure to disprove a hypothesis would be much more honest and convincing, wouldn&#039;t it?

&lt;strong&gt;Seth: If &quot;profit&quot; includes career advancement, salary increase, grant renewal, and so on, I think about 100% of testing is done with profit in mind. Almost always some results are more profitable than the others.&lt;/strong&gt;]]></description>
		<content:encoded><![CDATA[<p>Experience has shown, I believe, that this is a particularly glaring problem in the context of drug testing and development in the pharmaceutical industry.  Much of this is surely brought about by conflicts of interest (and a certain amount of corruption) which are endemic in this exceedingly profit-driven industry.  </p>
<p>Another issue is the common disregard of true scientific method (Popper anyone?) in the planning and conduct of testing because so much of the &#8220;testing&#8221; is done with profits in mind.  Shouldn&#8217;t the object (protocol) for whatever is being tested be to disprove a particular hypothesis, rather than allowing biases to creep in so that a certain desired result can be realized and money can be made?  A failure to disprove a hypothesis would be much more honest and convincing, wouldn&#8217;t it?</p>
<p><strong>Seth: If &#8220;profit&#8221; includes career advancement, salary increase, grant renewal, and so on, I think about 100% of testing is done with profit in mind. Almost always some results are more profitable than the others.</strong></p>
]]></content:encoded>
	</item>
	<item>
		<title>By: kxmoore</title>
		<link>http://blog.sethroberts.net/2013/09/10/the-blindness-of-scientists-the-real-problem-is-undetected-positives/#comment-1139323</link>
		<dc:creator><![CDATA[kxmoore]]></dc:creator>
		<pubDate>Tue, 10 Sep 2013 16:00:42 +0000</pubDate>
		<guid isPermaLink="false">http://blog.sethroberts.net/?p=11096#comment-1139323</guid>
		<description><![CDATA[i wonder if this test is replicable.  The implications are huge considering the explosion of obesity and it&#039;s related health effects.

http://www.ncbi.nlm.nih.gov/pubmed/22863169]]></description>
		<content:encoded><![CDATA[<p>i wonder if this test is replicable.  The implications are huge considering the explosion of obesity and it&#8217;s related health effects.</p>
<p><a href="http://www.ncbi.nlm.nih.gov/pubmed/22863169" rel="nofollow">http://www.ncbi.nlm.nih.gov/pubmed/22863169</a></p>
]]></content:encoded>
	</item>
	<item>
		<title>By: Tom</title>
		<link>http://blog.sethroberts.net/2013/09/10/the-blindness-of-scientists-the-real-problem-is-undetected-positives/#comment-1139322</link>
		<dc:creator><![CDATA[Tom]]></dc:creator>
		<pubDate>Tue, 10 Sep 2013 15:50:13 +0000</pubDate>
		<guid isPermaLink="false">http://blog.sethroberts.net/?p=11096#comment-1139322</guid>
		<description><![CDATA[A good illustration of your point:
http://well.blogs.nytimes.com/2013/09/10/myths-surround-breakfast-and-weight/]]></description>
		<content:encoded><![CDATA[<p>A good illustration of your point:<br />
<a href="http://well.blogs.nytimes.com/2013/09/10/myths-surround-breakfast-and-weight/" rel="nofollow">http://well.blogs.nytimes.com/2013/09/10/myths-surround-breakfast-and-weight/</a></p>
]]></content:encoded>
	</item>
	<item>
		<title>By: August</title>
		<link>http://blog.sethroberts.net/2013/09/10/the-blindness-of-scientists-the-real-problem-is-undetected-positives/#comment-1139296</link>
		<dc:creator><![CDATA[August]]></dc:creator>
		<pubDate>Tue, 10 Sep 2013 13:15:40 +0000</pubDate>
		<guid isPermaLink="false">http://blog.sethroberts.net/?p=11096#comment-1139296</guid>
		<description><![CDATA[Cheaper tests are good, unless the cheaper tests are computer models. We need cheaper real world tests.  Didn&#039;t you post a long time ago about the error rate of DNA computer models? I learned about the dubious nature of computer modeling via the intersection of politics and climatology.

&lt;strong&gt;Seth: Computer models aren&#039;t tests of theories, they are theories.&lt;/strong&gt;]]></description>
		<content:encoded><![CDATA[<p>Cheaper tests are good, unless the cheaper tests are computer models. We need cheaper real world tests.  Didn&#8217;t you post a long time ago about the error rate of DNA computer models? I learned about the dubious nature of computer modeling via the intersection of politics and climatology.</p>
<p><strong>Seth: Computer models aren&#8217;t tests of theories, they are theories.</strong></p>
]]></content:encoded>
	</item>
</channel>
</rss>

<!-- Performance optimized by W3 Total Cache. Learn more: http://www.w3-edge.com/wordpress-plugins/

Content Delivery Network via Amazon Web Services: S3: srblogfiles.s3.amazonaws.com

 Served from: blog.sethroberts.net @ 2014-10-12 23:17:05 by W3 Total Cache -->