<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0"
	xmlns:content="http://purl.org/rss/1.0/modules/content/"
	xmlns:wfw="http://wellformedweb.org/CommentAPI/"
	xmlns:dc="http://purl.org/dc/elements/1.1/"
	xmlns:atom="http://www.w3.org/2005/Atom"
	xmlns:sy="http://purl.org/rss/1.0/modules/syndication/"
	xmlns:slash="http://purl.org/rss/1.0/modules/slash/"
	xmlns:itunes="http://www.itunes.com/dtds/podcast-1.0.dtd"
xmlns:rawvoice="http://www.rawvoice.com/rawvoiceRssModule/"
>

<channel>
	<title>Seth&#039;s Blog &#187; statistics</title>
	<atom:link href="http://blog.sethroberts.net/category/statistics/feed/" rel="self" type="application/rss+xml" />
	<link>http://blog.sethroberts.net</link>
	<description>Personal Science, Self-Experimentation, Scientific Method</description>
	<lastBuildDate>Mon, 25 Aug 2014 20:18:36 +0000</lastBuildDate>
	<language>en-US</language>
		<sy:updatePeriod>hourly</sy:updatePeriod>
		<sy:updateFrequency>1</sy:updateFrequency>
	<generator>http://wordpress.org/?v=3.7.1</generator>
<!-- podcast_generator="Blubrry PowerPress/5.0.2" mode="simple" -->
	<itunes:summary>Personal Science, Self-Experimentation, Scientific Method</itunes:summary>
	<itunes:author>Seth&#039;s Blog</itunes:author>
	<itunes:explicit>no</itunes:explicit>
	<itunes:image href="http://blog.sethroberts.net/wp-content/plugins/powerpress/itunes_default.jpg" />
	<itunes:subtitle>Personal Science, Self-Experimentation, Scientific Method</itunes:subtitle>
	<image>
		<title>Seth&#039;s Blog &#187; statistics</title>
		<url>http://blog.sethroberts.net/wp-content/plugins/powerpress/rss_default.jpg</url>
		<link>http://blog.sethroberts.net/category/statistics/</link>
	</image>
	<item>
		<title>The Wisdom of Google: &#8220;Dessert&#8221;, &#8220;Honey&#8221; and &#8220;Fruit&#8221; Closer to &#8220;Dinner&#8221; than &#8220;Breakfast&#8221; or &#8220;Lunch&#8221;</title>
		<link>http://blog.sethroberts.net/2014/03/16/the-wisdom-of-google-dessert-honey-and-fruit-closer-to-dinner-than-breakfast-or-lunch/</link>
		<comments>http://blog.sethroberts.net/2014/03/16/the-wisdom-of-google-dessert-honey-and-fruit-closer-to-dinner-than-breakfast-or-lunch/#comments</comments>
		<pubDate>Sun, 16 Mar 2014 12:00:42 +0000</pubDate>
		<dc:creator><![CDATA[Seth Roberts]]></dc:creator>
				<category><![CDATA[honey & sleep]]></category>
		<category><![CDATA[statistics]]></category>

		<guid isPermaLink="false">http://blog.sethroberts.net/?p=13234</guid>
		<description><![CDATA[I have blogged many times that bedtime honey improves sleep. I learned this from Stuart King, an Australian musician. He also pointed out we eat dessert with dinner more than with other meals. which others who have described the honey effect have not said. The dessert observation suggests that other sweets, not just honey, improve [&#8230;]]]></description>
				<content:encoded><![CDATA[<p>I have <a href="http://blog.sethroberts.net/category/sleep/honey-sleep/" target="_blank">blogged many times</a> that bedtime honey improves sleep. I learned this from <a href="http://stuartkingmusic.wordpress.com/" target="_blank">Stuart King</a>, an Australian musician. He also pointed out we eat dessert with dinner more than with other meals. which others who have described the honey effect <a href="http://blog.sethroberts.net/2014/01/02/interview-with-mike-mcinnes-author-of-the-honey-diet/" target="_blank">have not said</a>. The dessert observation suggests that other sweets, not just honey, improve sleep. After I repeated the dessert observation, a friend said I of all people should know it isn&#8217;t universal. The Chinese don&#8217;t eat dessert, she said. Yes, I said, but where I lived in Beijing there seemed to be lots of sweets eaten in the evening, and lots of street vendors selling fruit in the evening.<span id="more-13234"></span></p>
<p>The honey-sleep connection helped me improve my sleep in other ways. I found my sleep got better if in addition to bedtime honey I ate fruit (e.g., banana) an hour or so before bedtime.  My sleep got even better if I ate something sweet, such as Yakult, an hour or so before that. Both observations implied that honey improved sleep because of the sugar. Nowadays I usually eat three sets of sweets: soon after dinner, mid-evening, and bedtime. I sleep very well every single night, better than ever before. These findings make sense if glycogen (stored glucose) is very important for sleep. My way of eating (three sets of sweets slightly spread out) may produce more glycogen at bedtime than similar ways of eating (e.g., eating the same sweets spread throughout the day).</p>
<p>Recently I realized that Stuart&#8217;s observation about dinner and dessert made a prediction: the word <em>dessert</em> should be better associated with the word <em>dinner</em> than the words <em>breakfast </em>and <em>lunch</em>. (A lot of talking/writing consists of describing reality.) I used Google to test this prediction. I counted the hits returned when I searched &#8220;dessert dinner&#8221;, &#8220;dessert breakfast&#8221;, and &#8220;dessert lunch&#8221;. The prediction turned out to be true: &#8220;dessert dinner&#8221; had a lot more hits than the other two combinations, even though <em>breakfast</em>, <em>lunch </em>and <em>dinner</em> are almost equally common.</p>
<p>I checked about forty other food words: Were they more associated with one meal than others? I found several interesting things.</p>
<p>1. It wasn&#8217;t just <em>dessert</em>. <em>Honey</em> and <em>fruit</em> were associated with <em>dinner</em> more than <em>breakfast</em> or <em>lunch</em>. The size of the association was very similar in the three cases. For almost all other food words I tested there was little or no association.</p>
<p><a href="http://srblogfiles.s3.amazonaws.com/wp-content/uploads/2014/03/2014-03-15-google-food-basic-effect.jpeg"><img class="aligncenter size-large wp-image-13241" alt="2014-03-15 google food basic effect" src="http://srblogfiles.s3.amazonaws.com/wp-content/uploads/2014/03/2014-03-15-google-food-basic-effect-591x300.jpeg" width="591" height="300" /></a></p>
<p>Here are examples of little or no association.</p>
<p><a href="http://srblogfiles.s3.amazonaws.com/wp-content/uploads/2014/03/2014-03-15-google-food-no-effect.jpeg"><img class="aligncenter size-large wp-image-13248" alt="2014-03-15 google food no effect" src="http://srblogfiles.s3.amazonaws.com/wp-content/uploads/2014/03/2014-03-15-google-food-no-effect-591x300.jpeg" width="591" height="300" /></a></p>
<p>2. There were some surprising associations, shown here.</p>
<p><a href="http://srblogfiles.s3.amazonaws.com/wp-content/uploads/2014/03/2014-03-15-google-food-surprises.jpeg"><img class="aligncenter size-large wp-image-13245" alt="2014-03-15 google food surprises" src="http://srblogfiles.s3.amazonaws.com/wp-content/uploads/2014/03/2014-03-15-google-food-surprises-591x300.jpeg" width="591" height="300" /></a></p>
<p>No surprise that <em>tea</em> is associated with <em>breakfast</em> but why is <em>potato </em>associated with <em>lunch</em>? French fries? Why is <em>nuts</em> associated with <em>dinner</em>? Do nuts contain something that improves sleep?</p>
<p>For each food I computed a &#8220;dinner effect&#8221; meaning the log(dinner count) minus the average of log(breakfast count) and log(lunch count). Here is a kind of histogram of those values.</p>
<p><a href="http://srblogfiles.s3.amazonaws.com/wp-content/uploads/2014/03/2014-03-15-google-food-histogram.jpeg"><img class="aligncenter size-large wp-image-13252" alt="2014-03-15 google food histogram" src="http://srblogfiles.s3.amazonaws.com/wp-content/uploads/2014/03/2014-03-15-google-food-histogram-591x300.jpeg" width="591" height="300" /></a></p>
<p>The outlier status of nuts, fruit, honey and dessert is clear.</p>
<p>These findings support (a) the original idea (because the original idea led to them), (b) the importance of the original idea (because the association is so clear) and (c) use of Google to learn what people do. Word associations are influenced by many things, no doubt; these results suggest actual behavior is a strong influence. Use of Google to study behavior is free, public, fast, and convenient.</p>
<p>I was surprised the results were so clear. I suspect the explanation is that sweets taste better closer to bedtime. Dessert, honey and fruit differ in many ways; the similarity of size of association suggests that the association is due to what they share (sugar).</p>
<p>I hereby give you permission to eat dessert with dinner.</p>
]]></content:encoded>
			<wfw:commentRss>http://blog.sethroberts.net/2014/03/16/the-wisdom-of-google-dessert-honey-and-fruit-closer-to-dinner-than-breakfast-or-lunch/feed/</wfw:commentRss>
		<slash:comments>17</slash:comments>
		</item>
		<item>
		<title>Researchers Fool Themselves: Water and Cognition</title>
		<link>http://blog.sethroberts.net/2013/07/25/how-researchers-fool-themselves-water-and-cognition/</link>
		<comments>http://blog.sethroberts.net/2013/07/25/how-researchers-fool-themselves-water-and-cognition/#comments</comments>
		<pubDate>Thu, 25 Jul 2013 12:00:56 +0000</pubDate>
		<dc:creator><![CDATA[Seth Roberts]]></dc:creator>
				<category><![CDATA[fallibility of experts]]></category>
		<category><![CDATA[statistics]]></category>

		<guid isPermaLink="false">http://blog.sethroberts.net/?p=11001</guid>
		<description><![CDATA[A recent paper about the effect of water on cognition illustrates a common way that researchers overstate the strength of the evidence, apparently fooling themselves. Psychology researchers at the University of East London and the University of Westminster did an experiment in which subjects didn&#8217;t drink or eat anything starting at 9 pm and the [&#8230;]]]></description>
				<content:encoded><![CDATA[<p>A <a href="http://www.frontiersin.org/Human_Neuroscience/10.3389/fnhum.2013.00363/full" target="_blank">recent paper about the effect of water on cognition</a> illustrates a common way that researchers overstate the strength of the evidence, apparently fooling themselves. Psychology researchers at the University of East London and the University of Westminster did an experiment in which subjects didn&#8217;t drink or eat anything starting at 9 pm and the next morning came to the testing room. All of them were given something to eat, but only half of them were given something to drink. They came in twice. On one week, subjects were given water to drink; on the other week, they weren&#8217;t given water. Half of the subjects were given water on the first week, half on the second. Then they gave subjects a battery of cognitive tests.</p>
<p>One result makes sense: subjects were faster on a simple reaction time test (press button when you see a light) after being given water, but only if they were thirsty. Apparently thirst slows people down. Maybe it&#8217;s distracting.</p>
<p>The other result emphasized by the authors doesn&#8217;t make sense: Water made subjects worse at a task called Intra-Extra Dimensional Set Shift. The task provided two measures (total trials and total errors) but the paper gives results only for total trials. The omission is not explained. (I asked the first author about this by email; she did not explain the omission.) On total trials, subjects given water did worse, <em>p</em> = 0.03. A surprising result: after persons go without water for quite a while, giving them water makes them worse.</p>
<p>This <em>p</em> value is not corrected for number of tests done. A table of results shows that 14 different measures were used. There was a main effect of water on two of them. One was the simple reaction time result; the other was the IED Stages Completed (IED = intra/extra dimensional) result. It is likely that the effect of water on simple reaction time was a &#8220;true positive&#8221; because the effect was influenced by thirst. In contrast, the IED Stages Completed effect wasn&#8217;t reliably influenced by thirst. Putting the simple reaction time result aside, there are 13 <em>p</em> values for the main effect of water; one is weakly reliable (<em>p</em> = 0.03).  If you do 20 independent tests, purely by chance one is likely to have <em>p</em> &lt; 0.05 at least once even when there are no true effects. <span style="font-size: 13px;">Taken together, there is no good reason to believe that water had main effects aside from the simple reaction time test. </span><span style="font-size: 13px;">The paper would be a good question for an elementary statistics class (&#8220;Question: If 13 tests are independent, and there are no true effects present, how likely will at least one be <em>p = </em>0.03 or better by chance? Answer: 1 &#8211; (0.97^13) = 0.33&#8243;). </span></p>
<p><span style="font-size: 13px;">I wrote to the first author (Caroline Edmonds) about this several days ago. My email asked two questions. She replied but failed to answer the question about number of tests. Her answer was written in haste; maybe she will address this question later.</span></p>
<p>A better analysis would have started by assuming that the 14 measures are unlikely to be independent. It would have done (or used) a factor analysis that condensed the 14 measures into (say) three factors. Then the researchers could ask if water affected each of the three factors. Far fewer tests, far more independent tests, far harder to fool yourself or cherry-pick.</p>
<p>The problem here &#8212; many tests, failure to correct for this or do an analysis with far fewer tests &#8212; is common but the analysis I suggest is, in experimental psychology papers, very rare. (I&#8217;ve never seen it.) Factor analysis is taught as part of survey psychology (psychology research that uses surveys, such as personality research), not as part of experimental psychology.  In the statistics textbooks I&#8217;ve seen, the problem of too many tests and correction for/reduction of number of tests isn&#8217;t emphasized. Perhaps it is a research methodology example of Gresham&#8217;s Law: methods that make it easier to find what you want (differences with <em>p</em> &lt; 0.05) drive out better methods.</p>
<p>Thanks to Allan Jackson.</p>
]]></content:encoded>
			<wfw:commentRss>http://blog.sethroberts.net/2013/07/25/how-researchers-fool-themselves-water-and-cognition/feed/</wfw:commentRss>
		<slash:comments>7</slash:comments>
		</item>
		<item>
		<title>Assorted Links</title>
		<link>http://blog.sethroberts.net/2012/10/07/assorted-links-213/</link>
		<comments>http://blog.sethroberts.net/2012/10/07/assorted-links-213/#comments</comments>
		<pubDate>Sun, 07 Oct 2012 12:00:10 +0000</pubDate>
		<dc:creator><![CDATA[Seth Roberts]]></dc:creator>
				<category><![CDATA[health care]]></category>
		<category><![CDATA[health care stagnation]]></category>
		<category><![CDATA[statistics]]></category>
		<category><![CDATA[Vitamin D3 and sleep]]></category>

		<guid isPermaLink="false">http://blog.sethroberts.net/?p=7743</guid>
		<description><![CDATA[someone agrees with me that &#8220;correlation does not equal causation&#8221; is not great wisdom Vitamin D did not prevent colds. One more Vitamin D experiment that failed to have subjects take the Vitamin D early in the morning &#8212; the time it appears most likely to have a good effect. The rise and fall of [&#8230;]]]></description>
				<content:encoded><![CDATA[<ul>
<li><a href="http://www.slate.com/articles/health_and_science/science/2012/10/correlation_does_not_imply_causation_how_the_internet_fell_in_love_with_a_stats_class_clich_.html">someone agrees with me</a> that &#8220;correlation does not equal causation&#8221; is not great wisdom</li>
<li><a href="http://www.latimes.com/health/boostershots/la-heb-vitamin-d-does-not-prevent-colds-infections-study-20121002,0,377309.story">Vitamin D did not prevent colds</a>. One more Vitamin D experiment that failed to have subjects take the Vitamin D early in the morning &#8212; the time it appears most likely to have a good effect.</li>
<li><a href="http://davidhealy.org/the-madness-of-north-wales/?utm_source=feedburner&amp;utm_medium=feed&amp;utm_campaign=Feed%3A+DrDavidHealy+%28Dr.+David+Healy%29">The rise and fall of schizophrenia</a>. &#8220;Compared to any other medical disease, uniquely patients with schizophrenia in many ways fare far worse now than a century ago.&#8221;</li>
<li><a href="http://www.washingtonpost.com/wp-dyn/content/article/2005/06/26/AR2005062601091.html">The healing power of social networks</a>. &#8220;People with schizophrenia . . . do far better in poorer nations such as India, Nigeria and Colombia than in Denmark, England and the United States.&#8221;</li>
<li><a href="http://www.bmj.com/content/345/bmj.e6230?etoc=">Rampant overtreatment</a>.</li>
</ul>
<p>Thanks to Bryan Castañeda.</p>
]]></content:encoded>
			<wfw:commentRss>http://blog.sethroberts.net/2012/10/07/assorted-links-213/feed/</wfw:commentRss>
		<slash:comments>4</slash:comments>
		</item>
		<item>
		<title>The Growth of Personal Science: Implications For Statistics</title>
		<link>http://blog.sethroberts.net/2012/09/30/the-growth-of-personal-science-implications-for-statistics/</link>
		<comments>http://blog.sethroberts.net/2012/09/30/the-growth-of-personal-science-implications-for-statistics/#comments</comments>
		<pubDate>Sun, 30 Sep 2012 12:00:16 +0000</pubDate>
		<dc:creator><![CDATA[Seth Roberts]]></dc:creator>
				<category><![CDATA[general]]></category>
		<category><![CDATA[personal science]]></category>
		<category><![CDATA[statistics]]></category>

		<guid isPermaLink="false">http://blog.sethroberts.net/?p=7668</guid>
		<description><![CDATA[I have just submitted a paper to Statistical Science called &#8220;The Growth of Personal Science: Implications For Statistics&#8221;. The core of the paper is examples, mostly my work (on flaxseed oil, butter, standing, and so on). There is also a section on the broad lessons of the examples &#8212; what can be learned from them [&#8230;]]]></description>
				<content:encoded><![CDATA[<p>I have just submitted <a href="http://srblogfiles.s3.amazonaws.com/wp-content/uploads/2012/09/2012-09-24-The-Growth-of-Personal-Science-Implications-For-Statistics.pdf">a paper</a> to <em>Statistical Science</em> called &#8220;The Growth of Personal Science: Implications For Statistics&#8221;. The core of the paper is examples, mostly my work (on flaxseed oil, butter, standing, and so on). There is also a section on the broad lessons of the examples &#8212; what can be learned from them in addition to the subject-matter conclusions (e.g., butter makes me faster at arithmetic). The paper grew out of a talk I gave at the Joint Statistical Meetings a few years ago, as part of a session organized by Hadley Wickham, a professor of statistics at Rice University.<span id="more-7668"></span></p>
<p>I call this stuff<em> personal science</em>  (science done to help yourself), a new term, rather than <em>self-experimentation</em>, the old term, partly because a large amount of self-experimentation &#8212; until recently, almost all of it &#8212; is not personal science but professional science (science done as part of a job). Now and then, professional scientists or doctors or dentists have done their job using themselves as a subject. For example, a dentist tests a new type of anesthetic on himself. That&#8217;s self-experimentation but not personal science. Moreover, plenty of personal science is not self-experimentation.  An example is a mother reading the scientific literature <a href="http://boingboing.net/2012/01/10/tonsillectomy-confidential-do.html">to decide if her son should get a tonsillectomy</a>. It is personal science, not professional self-experimentation, whose importance has been underestimated.</p>
<p>An old term for personal science might be <em>amateur science</em>. In almost all areas of human endeavor, amateur work doesn&#8217;t matter. Cars are invented, designed and built entirely by professionals. Household products are invented, designed and built entirely by professionals. The food I eat comes entirely from professionals. And so on. Adam Smith glorified this (&#8220;division of labor&#8221; &#8212; a better name is division of expertise). There are, however, two exceptions: books and science. I read a substantial number of books not by professional writers and my own personal science has had a huge effect on my life. As a culture, we understand the importance of non-professional book writers. We have yet to grasp the importance of personal scientists.</p>
<p>Professional science is a big enterprise. Billions of dollars in research grants, hundreds of billions of dollars of infrastructure and equipment and libraries, perhaps a few hundred thousand people with full-time jobs, working year after year for hundreds of years. Presumably they are working hard, have been working hard, to expand what we know on countless topics, including sleep, weight control, nutrition, the immune system, and so on. Given all this, the fact that one person (me) could make ten or so discoveries that make a difference (in my life) is astonishing &#8212; or, at least, hard to explain. How could an amateur (me &#8212; my personal science, e.g., about sleep is outside my professional area of expertise) possibly find something that professional scientists, with their vastly greater resources and knowledge and experience, have missed? One discovery &#8212; maybe I was lucky. Two discoveries &#8212; maybe I was very very very lucky. Three or more discoveries &#8212; how can this possibly be?</p>
<p>Professional scientists have several advantages over personal scientists (funding, knowledge, infrastructure, etc.). On the other hand, personal scientists have several advantages over professional scientists. They have more freedom. A personal scientist can seriously study &#8220;crazy&#8221; ideas. A professional scientist cannot. Personal scientists also have a laser-sharp focus: They care only about self-improvement. Professional scientists no doubt want to make the world a better place, but they have other goals as well: getting a raise, keeping their job, earning and keeping the respect of their colleagues, winning awards, and so on. Personal scientists also have more time: They can study a problem for as long as it takes. Professional scientists, however, must produce a steady stream of papers. To spend ten years on one paper would be to kiss their career goodbye. The broad interest of my personal science is that my success suggests the advantages of personal science may in some cases outweigh the advantages of professional science. Which most people would considered impossible.</p>
<p>If this sounds interesting, I invite you to read my paper and comment. I am especially interested in suggestions for improvement. There is plenty of time to improve the final product &#8212; and no doubt plenty of room for improvement.</p>
]]></content:encoded>
			<wfw:commentRss>http://blog.sethroberts.net/2012/09/30/the-growth-of-personal-science-implications-for-statistics/feed/</wfw:commentRss>
		<slash:comments>2</slash:comments>
		</item>
		<item>
		<title>Assorted Links</title>
		<link>http://blog.sethroberts.net/2012/06/13/assorted-links-183/</link>
		<comments>http://blog.sethroberts.net/2012/06/13/assorted-links-183/#comments</comments>
		<pubDate>Wed, 13 Jun 2012 12:00:57 +0000</pubDate>
		<dc:creator><![CDATA[Seth Roberts]]></dc:creator>
				<category><![CDATA[Assorted Links]]></category>
		<category><![CDATA[books]]></category>
		<category><![CDATA[statistics]]></category>

		<guid isPermaLink="false">http://blog.sethroberts.net/?p=6808</guid>
		<description><![CDATA[Hospital costs at one hospital over 200 years (via Marginal Revolution). The graph of hospital costs versus year illustrates what you should never do: make a graph like that using an unlogged (raw) y axis (cost). It is nearly impossible &#8212; or actually impossible &#8212; to learn anything from the low numbers since they are [&#8230;]]]></description>
				<content:encoded><![CDATA[<ul>
<li><a href="http://www.nejm.org/doi/pdf/10.1056/NEJMp1202628">Hospital costs at one hospital over 200 years</a> (via <a href="http://marginalrevolution.com/marginalrevolution/2012/06/assorted-links-479.html">Marginal Revolution</a>). The graph of hospital costs versus year illustrates what you should never do: make a graph like that using an unlogged (raw) y axis (cost). It is nearly impossible &#8212; or actually impossible &#8212; to learn anything from the low numbers since they are so close to zero.  <em>New England of Journal of Medicine </em>editors need better statistical advice.</li>
<li><a href="http://newyork.grubstreet.com/2012/06/how-to-cook-with-marmite-vegemite.html">Cooking with Marmite</a>.</li>
<li><a href="http://www.westonaprice.org/blogs/kdaniel/2011/12/27/ivegetarian2-the-eating-disorders-of-steve-jobs/">Steve Jobs, orthorexic</a>.</li>
<li><a href="http://oakblue.wordpress.com/2010/09/19/telgi-and-the-fake-stamp-paper-scam/">The Telgi fake stamp paper scam</a>.</li>
<li><a href="http://www.ryanholiday.net/announcing-my-first-book-trust-me-im-lying-and-the-preorder-campaign/">preorder <em>Trust Me I&#8217;m Lying </em> by Ryan Holiday</a></li>
</ul>
]]></content:encoded>
			<wfw:commentRss>http://blog.sethroberts.net/2012/06/13/assorted-links-183/feed/</wfw:commentRss>
		<slash:comments>3</slash:comments>
		</item>
		<item>
		<title>Usual Drug Trial Analyses Insensitive to Rare Improvement</title>
		<link>http://blog.sethroberts.net/2012/05/20/usual-drug-trial-analyses-ignore-possibility-of-rare-improvement/</link>
		<comments>http://blog.sethroberts.net/2012/05/20/usual-drug-trial-analyses-ignore-possibility-of-rare-improvement/#comments</comments>
		<pubDate>Sun, 20 May 2012 12:00:20 +0000</pubDate>
		<dc:creator><![CDATA[Seth Roberts]]></dc:creator>
				<category><![CDATA[statistics]]></category>

		<guid isPermaLink="false">http://blog.sethroberts.net/?p=6669</guid>
		<description><![CDATA[In a comment on an article in The Scientist, someone tells a story with profound implications: I participated in 1992 NCI SWOG 9005 Phase 3 [clinical trial of] Mifepristone for recurrent meningioma. The drug put my tumor in remission when it regrew post surgery. However, other more despairing patients had already been grossly weakened by [&#8230;]]]></description>
				<content:encoded><![CDATA[<p>In <a href="http://the-scientist.com/2012/05/01/data-diving/#disqus_thread">a comment on an article in <em>The Scientist</em></a>, someone tells a story with profound implications:</p>
<blockquote><p>I participated in 1992 NCI SWOG 9005 Phase 3 [clinical trial of] Mifepristone for recurrent meningioma. The drug put my tumor in remission when it regrew post surgery. However, other more despairing patients had already been grossly weakened by multiple brain surgeries and prior standard brain radiation therapy which had failed them before they joined the trial.  They were really not as young, healthy and strong as I was when I decided to volunteer for a &#8220;state of the art&#8221; drug therapy upon my first recurrence.  . . .  I could not get the names of the anonymous members of the Data and Safety Monitoring committee who closed the trial as &#8220;no more effective than placebo&#8221;. I had flunked the placebo the first year and my tumor did not grow for the next three years I was allowed to take the real drug. I finally managed to get FDA approval to take the drug again in Feb 2005 and my condition has remained stable ever since according to my MRIS.</p></blockquote>
<p>Apparently the drug did not work for most participants in the trial &#8212; leading to the conclusion &#8220;no mnore effective than placebo&#8221; &#8212; but it did work for him.</p>
<p>The statistical tests used to decide if a drug works are not sensitive to this sort of thing &#8212; most patients not helped, a few patients helped. (Existing tests, such as the t test, work best with normality of both groups, treatment and placebo, whereas this outcome produces non-normality of the treatment group, which reduces test sensitivity.) It is quite possible to construct analyses that would be more sensitive to this than existing tests, but this has not been done. It is quite possible to run a study that produces <strong>for each patient</strong> a p value for the null hypothesis of no effect (a number that helps you decide if that particular patient has been helped) but this too has not been done. </p>
<p>Since these new analyses would <strong>benefit</strong> drug companies, their absence is curious.  </p>
]]></content:encoded>
			<wfw:commentRss>http://blog.sethroberts.net/2012/05/20/usual-drug-trial-analyses-ignore-possibility-of-rare-improvement/feed/</wfw:commentRss>
		<slash:comments>4</slash:comments>
		</item>
		<item>
		<title>Gene Linked to Autism?</title>
		<link>http://blog.sethroberts.net/2012/04/08/gene-linked-to-autism/</link>
		<comments>http://blog.sethroberts.net/2012/04/08/gene-linked-to-autism/#comments</comments>
		<pubDate>Sun, 08 Apr 2012 12:00:40 +0000</pubDate>
		<dc:creator><![CDATA[Seth Roberts]]></dc:creator>
				<category><![CDATA[autism]]></category>
		<category><![CDATA[statistics]]></category>

		<guid isPermaLink="false">http://blog.sethroberts.net/?p=6270</guid>
		<description><![CDATA[An article in the New York Times describes research that supposedly linked a rare gene mutation to autism: Dr. Matthew W. State, a professor of genetics and child psychiatry at Yale, led a team that looked for de novo mutations [= mutations that are not in the parents] in 200 people who had been given [&#8230;]]]></description>
				<content:encoded><![CDATA[<p><a href="http://www.nytimes.com/2012/04/05/health/research/scientists-link-rare-gene-mutations-to-heightened-risk-of-autism.html?_r=1&amp;pagewanted=all#">An article in the <em>New York Times</em></a> describes research that supposedly linked a rare gene mutation to autism:</p>
<blockquote><p>Dr. Matthew W. State, a professor of genetics and child psychiatry at Yale, led a team that looked for de novo mutations [= mutations that are not in the parents] in 200 people who had been given an autism diagnosis, as well as in parents and siblings who showed no signs of the disorder. The team found that two unrelated children with autism in the study had de novo mutations in the same gene — and nothing similar in those without a diagnosis.</p>
<p>“That is like throwing a dart at a dart board with 21,000 spots and hitting the same one twice,” Dr. State said. “The chances that this gene is related to autism risk is something like 99.9999 percent.”</p></blockquote>
<p>It is like throwing 200 darts at a dart board with 21,000 spots (the number of genes) and hitting the same one twice. (Each person has about 1 de novo mutation.) What are the odds of that? If all spots are equally likely to be hit, then the probability is about 0.6. More likely than not. (Dr. State seems to think it is extremely unlikely.) This is a variation on <a href="http://en.wikipedia.org/wiki/Birthday_problem">the birthday paradox</a>. If there are 23 people in a room, it is 50/50 that two of them will share a birthday.</p>
<p>When Dr. State says, &#8220;The chances that this gene is related to autism risk is something like 99.9999 percent,&#8221; he is making an elementary mistake. He has taken a very low <em>p</em> value (maybe 0.000001) from a statistical test to indicate the likelihood that the null hypothesis (no association with autism) is true. <em>P</em> values indicate strength of evidence, not probability of truth.</p>
<p>One way to look at the evidence is that there is a group of 200 people (with an autism diagnosis) among whom two have a certain mutation and another group of about 600 people (their parents and siblings) none of whom have that mutation. If two instances of the mutation were randomly distributed among 800 people what are the odds that both instances would be in any pre-defined group of 200 of the 800 people (defined, say, by the letters in their first name)? The chance of this happening is 1/16. Not strong evidence of an association between the mutation and the actual pre-defined group (autism diagnosis).</p>
<p>Another study published at the same time found an link between autism and a mutation in the same gene identified by Dr. State&#8217;s group but again the association was weak. It may be a more subtle example of the birthday paradox: If twenty groups of genetics researchers are looking for a gene linked to autism, what are the odds that two of them will happen upon the same gene by chance?</p>
<p>If the gene with the de novo mutations is actually linked to autism, then we will have insight into the cause of 1% of the 200 autism cases Dr. Smart&#8217;s group studied. When genetics researchers try so hard and come up with so little, it increases my belief that the main causes of autism are environmental.</p>
<p>Thanks to Bryan Castañeda.</p>
]]></content:encoded>
			<wfw:commentRss>http://blog.sethroberts.net/2012/04/08/gene-linked-to-autism/feed/</wfw:commentRss>
		<slash:comments>2</slash:comments>
		</item>
		<item>
		<title>&#8220;Seth, How Do You Track and Analyze Your Data?&#8221;</title>
		<link>http://blog.sethroberts.net/2012/03/20/seth-how-do-you-track-and-analyze-your-data/</link>
		<comments>http://blog.sethroberts.net/2012/03/20/seth-how-do-you-track-and-analyze-your-data/#comments</comments>
		<pubDate>Tue, 20 Mar 2012 12:00:24 +0000</pubDate>
		<dc:creator><![CDATA[Seth Roberts]]></dc:creator>
				<category><![CDATA[scientific method]]></category>
		<category><![CDATA[statistics]]></category>

		<guid isPermaLink="false">http://blog.sethroberts.net/?p=6038</guid>
		<description><![CDATA[A reader asks: I haven&#8217;t found much on your blog commenting on tools you use to track your data. Any recommendations? Have you tried smart phones? For example, I have tried tracking fifteen variables daily via the iPhone app Moodtracker, the only one I found that can track and graph multiple variables and also give [&#8230;]]]></description>
				<content:encoded><![CDATA[<p>A reader asks:</p>
<blockquote><p>I haven&#8217;t found much on your blog commenting on tools you use to track your data. Any recommendations? Have you tried smart phones? For example, I have tried tracking fifteen variables daily via the iPhone app Moodtracker, the only one I found that can track and graph multiple variables and also give you automated reminders to submit data. There are other variants (Data Logger, Daytum) that will graph one variable (say, miles run per day), but Moodtracker is the only app I&#8217;ve found that lets you analyze multiple variables.</p></blockquote>
<p>I use R on a laptop to track and analyze my data.  I write functions for doing this &#8212; they are not built-in. This particular reader hadn&#8217;t heard of R. It is free and the most popular software among statisticians. It has lots of built-in functions (although not for data collection &#8212; apparently statisticians rarely collect data) and provides lots of control over the graphs you make, which is very important. R also has several programs for fitting loess curves to your data. Loess is a kind of curve-fitting. There is a vast amount of R-related material, including introductory stuff, <a href="http://www.r-bloggers.com/">here</a>.</p>
<p>To give an example, after I weigh myself each morning (I have three scales), I enter the three weights into R, which stores them and makes a graph. That&#8217;s on the simple side. At the other extreme are the various mental tests I&#8217;ve written (e.g., arithmetic) to measure how well my brain is working. The programs for doing the test are in R, the data is stored in R, and analyzed with R.</p>
<p>The analysis possibilities (e.g., the graphs you can make, your control over those graphs) I&#8217;ve seen on smart phone apps are hopelessly primitive for what I want to do. The people who write the analysis software seem to know almost nothing about data analysis. For example, I use a website called <a href="https://www.ranktracer.com">RankTracer</a> to track the Amazon ranking of <em>The Shangri-La Diet</em>. Whoever wrote the software is so clueless the rank versus time graphs don&#8217;t even show log ranks.</p>
<p>I don&#8217;t know what the future holds. In academic psychology, there is near-total reliance on statistical packages (e.g., SPSS) that are so limited perhaps they can extract only half of the information in the usual data. There are many graphs you&#8217;d like to make that it is impossible to make. SPSS may not even have loess, for example. Yet I see no sign of this changing. Will personal scientists want to learn more from their data than psychology professors (and therefore be motivated to go beyond pre-packaged analyses)? I don&#8217;t know.</p>
]]></content:encoded>
			<wfw:commentRss>http://blog.sethroberts.net/2012/03/20/seth-how-do-you-track-and-analyze-your-data/feed/</wfw:commentRss>
		<slash:comments>5</slash:comments>
		</item>
		<item>
		<title>Causal Reasoning in Science: Don&#8217;t Dismiss Correlations</title>
		<link>http://blog.sethroberts.net/2011/07/07/causal-reasoning-in-science/</link>
		<comments>http://blog.sethroberts.net/2011/07/07/causal-reasoning-in-science/#comments</comments>
		<pubDate>Thu, 07 Jul 2011 12:00:04 +0000</pubDate>
		<dc:creator><![CDATA[]]></dc:creator>
				<category><![CDATA[evidence snobs]]></category>
		<category><![CDATA[ignorance]]></category>
		<category><![CDATA[scientific method]]></category>
		<category><![CDATA[self-experimentation]]></category>
		<category><![CDATA[statistics]]></category>
		<category><![CDATA[Andrew Gelman]]></category>
		<category><![CDATA[causality]]></category>
		<category><![CDATA[experimental design]]></category>

		<guid isPermaLink="false">http://blog.sethroberts.net/?p=3241</guid>
		<description><![CDATA[In a paper (and blog post), Andrew Gelman writes: As a statistician, I was trained to think of randomized experimentation as representing the gold standard of knowledge in the social sciences, and, despite having seen occasional arguments to the contrary, I still hold that view, expressed pithily by Box, Hunter, and Hunter (1978) that “To [&#8230;]]]></description>
				<content:encoded><![CDATA[<p>In <a href="http://www.stat.columbia.edu/~gelman/research/published/yalecausal2.pdf">a paper</a> (and <a href="http://www.stat.columbia.edu/~cook/movabletype/archives/2010/08/no_understandin.html">blog post</a>), Andrew Gelman writes:</p>
<blockquote><p>As a statistician, I was trained to think of randomized experimentation as representing the gold standard of knowledge in the social sciences, and, despite having seen occasional arguments to the contrary, I still hold that view, expressed pithily by Box, Hunter, and Hunter (1978) that “To find out what happens when you change something, it is necessary to change it.”</p></blockquote>
<p>Box, Hunter, and Hunter (1978) (a book called <em>Statistics for Experimenters</em>) is well-regarded by statisticians. Perhaps Box, Hunter, and Hunter, and Andrew, were/are unfamiliar with another quote (modified <a href="http://www.todayinsci.com/B/Beveridge_WIB/BeveridgeWIB-Quotations.htm">from Beveridge</a>): &#8220;Everyone believes an experiment except the experimenter; no one believes a theory except the theorist.&#8221;<span id="more-3241"></span></p>
<p>Box, Hunter, and Hunter were/are theorists, in the sense that they don&#8217;t do experiments (or even collect data) themselves. And their book has a massive blind spot. It contains 500 pages on how to test ideas and not one page &#8212; not one sentence &#8212; on how to come up with ideas worth testing. Which is just as important. Had they considered both goals &#8212; idea generation and idea testing &#8212; they would have written a different book. It would have said much more about graphical data analysis and  simple experimental designs, and, I hope, would not have contained the flat statement (&#8220;To find out what happens &#8230;&#8221;) Andrew quotes.</p>
<p>&#8220;To find out what happens when you change something, it is <strong>necessary</strong> to change it.” It&#8217;s not &#8220;necessary&#8221; because belief in causality, like all belief, is graded: it can take on an infinity of values, from zero (&#8220;can&#8217;t possibly be true&#8221;) to one (&#8220;I&#8217;m completely sure&#8221;). And belief changes gradually. In my experience, significant (substantially greater than zero) belief in the statement <em>A changes B</em> usually starts with the observation of a correlation between A and B. For example, I began to believe that one-legged standing would make me sleep better after I slept unusually well one night and realized that the previous day I had stood on one leg (which I almost never do). That correlation made <em>one-legged standing improves sleep</em> more plausible, taking it from near zero to some middle value of belief (&#8220;might be true, might not be true&#8221;) <a href="http://blog.sethroberts.net/2011/03/22/effect-of-one-legged-standing-on-sleep/">Experiments in which I stood on one leg various amounts</a> pushed my belief in the statement close to one (&#8220;sure it&#8217;s true&#8221;). In other words, my journey &#8220;to find out what happens&#8221; to my sleep when I stood on one leg <strong>began</strong> with a correlation. Not an experiment. To push belief from high (say, 0.8) to really high (say, 0.99) you do need experiments. But to push belief from low (say, 0.0001) to medium (say, 0.5), you don&#8217;t need experiments. To fail to understand how beliefs begin, as Box et al. apparently do, is to miss something really important.</p>
<p>Science is about increasing certainty &#8212; about learning. You can learn from any observation, as distasteful as that may be to <a href="http://blog.sethroberts.net/category/scientific-method/evidence-snobs/">evidence snobs</a>. By saying that experiments are &#8220;necessary&#8221; to find out something, Box et al. said the opposite of <em>you can learn from any observation</em>. Among shades of gray, they drew a line and said &#8220;this side white, that side black&#8221;.</p>
<p>The Box et al. attitude makes a big difference in practice. It has two effects:</p>
<ol>
<li>Too-complex research designs. Just as researchers undervalue correlations, they undervalue simple experiments. They overdesign. Their experiments (or data collection efforts) cost far more and take much longer than they should. The self-experimentation I&#8217;ve learned so much from, for example, is undervalued. This is one reason I learned so much from it &#8212; because it was new.</li>
<li>Existing evidence is undervalued, <a href="http://blog.sethroberts.net/2007/08/08/something-is-better-than-nothing-part-2/">even ignored</a>, because it doesn&#8217;t meet some standard of purity.</li>
</ol>
<p>In my experience, both tendencies (too-complex designs, undervaluation of evidence) are very common. In the last ten years, for example, almost every proposed experiment I&#8217;ve learned about has been more complicated than I think wise.</p>
<p>Why did Box, Hunter, and Hunter get it so wrong? I think it gets back to <a href="http://sethroberts.net/articles/2010%20The%20unreasonable%20effectiveness%20of%20my%20self-experimentation.pdf">the job/hobby distinction</a>. As I said, Box et al. didn&#8217;t generate data themselves. They got it from professional researchers &#8212; mostly engineers and scientists in academia or industry. Those engineers and scientists have jobs. Their job is to do research. They need regular publications. Hypothesis testing is good for that. You do an experiment to test an idea, you publish the result. Hypothesis generation, on the other hand, is too uncertain. It&#8217;s rare. It&#8217;s like tossing a coin, hoping for heads, when the chance of heads is tiny. Ten researchers might work for ten years, tossing coins many times, and generate only one new idea. Perhaps all their work, all that coin tossing, was equally good. But only one researcher came up with the idea. Should only one researcher get credit? Should the rest get fired, for wasting ten years? You see the problem, and so do the researchers themselves. So hypothesis generation is essentially ignored by professionals because they have jobs. They don&#8217;t go to statisticians asking: <em>How can I better generate ideas?</em> They do ask: <em>How can I better test ideas?</em> So statisticians get a biased view of what matters, do biased research (ignoring idea generation), and write biased books (that don&#8217;t mention idea generation).</p>
<p>My self-experimentation taught me that the Box et al. view of experimentation (and of science &#8212; that it was all about hypothesis testing) was seriously incomplete. It could do so because it was like a hobby. I had no need for publications or other steady output. Over thirty years, I collected a lot of data, did a lot of fast-and-dirty experiments, noticed informative correlations (&#8220;accidental observations&#8221;) many times, and came to see the great importance of correlations in learning about causality.</p>
<p>&nbsp;</p>
<p>&nbsp;</p>
<p>&nbsp;</p>
<p>&nbsp;</p>
<p>&nbsp;</p>
<p>&nbsp;</p>
<p>&nbsp;</p>
<p>&nbsp;</p>
]]></content:encoded>
			<wfw:commentRss>http://blog.sethroberts.net/2011/07/07/causal-reasoning-in-science/feed/</wfw:commentRss>
		<slash:comments>9</slash:comments>
		</item>
		<item>
		<title>The Problem with Evidence-Based Medicine</title>
		<link>http://blog.sethroberts.net/2010/07/11/more-about-medical-decision-making/</link>
		<comments>http://blog.sethroberts.net/2010/07/11/more-about-medical-decision-making/#comments</comments>
		<pubDate>Sun, 11 Jul 2010 08:58:28 +0000</pubDate>
		<dc:creator><![CDATA[]]></dc:creator>
				<category><![CDATA[evidence-based medicine]]></category>
		<category><![CDATA[health care]]></category>
		<category><![CDATA[statistics]]></category>

		<guid isPermaLink="false">http://www.blog.sethroberts.net/2010/07/11/more-about-medical-decision-making/</guid>
		<description><![CDATA[In a recent post I said that med school professors cared about process (doing things a &#8220;correct&#8221; way) rather than result (doing things in a way that produces the best possible outcomes). Feynman called this sort of thing &#8220;cargo-cult science&#8220;. The problem is that there is little reason to think the med-school profs&#8217; &#8220;correct&#8221; way [&#8230;]]]></description>
				<content:encoded><![CDATA[<p>In <a href="http://www.blog.sethroberts.net/2010/07/09/does-lithium-slow-als/">a recent post</a> I said that med school professors cared about process (doing things a &#8220;correct&#8221; way) rather than result (doing things in a way that produces the best possible outcomes). Feynman called this sort of thing &#8220;<a href="http://www.lhup.edu/~DSIMANEK/cargocul.htm">cargo-cult science</a>&#8220;. The problem is that there is little reason to think the med-school profs&#8217; &#8220;correct&#8221; way (evidence-based medicine) works better than the &#8220;wrong&#8221; way it replaced (reliance on clinical experience) and considerable reason to think it isn&#8217;t obvious which way is better.</p>
<p>After I wrote the previous post, I came across an example of the thinking I criticized. On bloggingheads.tv, during <a href="http://bloggingheads.tv/diavlogs/23344">a conversation</a> between Peter Lipson (a practicing doctor) and Isis The Scientist (a &#8220;physiologist at a major research university&#8221; who <a href="http://scienceblogs.com/isisthescientist/">blogs</a> at ScienceBlogs), Isis said this:</p>
<blockquote><p>I had an experience a couple days ago with a clinician that was very valuable. He said to me, &#8220;In my experience this is the phenomenon that we see after this happens.&#8221; And I said, &#8220;Really? I never thought of that as a possibility but that totally fits in the scheme of my model.&#8221; On the one hand I&#8217;ve accepted his experience as evidence. On the other hand I&#8217;ve totally written it off as bullshit because there isn&#8217;t a <em>p</em> value attached to it.</p></blockquote>
<p>Isis doesn&#8217;t understand that this &#8220;<em>p </em>value&#8221; she wants so much comes with a sensitivity filter attached. It is not neutral. To get it you do extensive calculations. The end result (the <em>p </em>value) is more sensitive to some treatment effects than others in the sense that some treatment effects will generate smaller (better) <em>p </em>values than other treatment effects of the same strength, just as our ears are more sensitive to some frequencies than others.</p>
<p>Our ears are most sensitive around the frequency of voices. They do a good job of detecting what we want to detect. What neither Isis nor any other evidence-based-medicine proponent knows is whether the particular filter they endorse is sensitive to the treatment effects that actually exist. It&#8217;s entirely possible and even plausible that the filter that they believe in is <em>insensitive</em> to actual treatment effects. They may be listening at the wrong frequency, in other words. The useful information may be at a different frequency.</p>
<p>The usual statistics (mean, etc.) are most sensitive to treatment effects that change each person in the population by the same amount. They are much less sensitive to treatment effects that change only a small fraction of the population. In contrast, the &#8220;clinical judgment&#8221; that Isis and other evidence-based-medicine advocates deride is highly sensitive to treatments that change only a small fraction of the population &#8212; what some call anecdotal evidence. Evidence-based medicine is presented as science replacing nonsense but in fact it is one filter replacing another.</p>
<p>I suspect that actual treatment effects have a power-law distribution (a few helped a lot, a large fraction helped little or not at all) and that a filter resembling &#8220;clinical judgment&#8221; does a better job with such distributions. But that remains to be seen. My point here is just that it is an empirical question which filter works best. An empirical question that hasn&#8217;t been answered.</p>
]]></content:encoded>
			<wfw:commentRss>http://blog.sethroberts.net/2010/07/11/more-about-medical-decision-making/feed/</wfw:commentRss>
		<slash:comments>11</slash:comments>
		</item>
		<item>
		<title>Does Lithium Slow ALS?</title>
		<link>http://blog.sethroberts.net/2010/07/09/does-lithium-slow-als/</link>
		<comments>http://blog.sethroberts.net/2010/07/09/does-lithium-slow-als/#comments</comments>
		<pubDate>Sat, 10 Jul 2010 06:57:08 +0000</pubDate>
		<dc:creator><![CDATA[]]></dc:creator>
				<category><![CDATA[health care]]></category>
		<category><![CDATA[statistics]]></category>

		<guid isPermaLink="false">http://www.blog.sethroberts.net/2010/07/09/does-lithium-slow-als/</guid>
		<description><![CDATA[In 2008, an article in Proceedings of the National Academy of Sciences (PNAS) reported that lithium had slowed the progression of amyotrophic lateral sclerosis (ALS), which is always fatal. This article describes several attempts to confirm that effect of lithium. Three studies were launched by med school professors. In addition, patients at PatientsLikeMe also organized [&#8230;]]]></description>
				<content:encoded><![CDATA[<p>In 2008, an article in <em>Proceedings of the National Academy of Sciences</em> (PNAS) reported that lithium had slowed the progression of amyotrophic lateral sclerosis (ALS), which is always fatal. <a href="http://www.scientificamerican.com/article.cfm?id=control-group-patients-ta">This article</a> describes several attempts to confirm that effect of lithium. Three studies were launched by med school professors. In addition, patients at <a href="http://www.patientslikeme.com/">PatientsLikeMe</a> also organized a test.</p>
<p>One of Nassim Taleb&#8217;s complaints about finance professors is their use of VAR (value at risk)Â  to measure the riskiness of investments. It&#8217;s still being taught at business schools, he says. VAR assumes that fluctuations have a certain distribution. The distributions actually assumed turned out to grossly underestimate risk. VAR has helped many finance professionals take risks they shouldn&#8217;t have taken. It would have been wise for finance professors to wonder how well VAR does in practice, thereby to judge the plausibility of the assumed distribution. This might seem obvious. Likewise, the response to the PNAS paper revealed two problems that might seem obvious:</p>
<p>1. <strong>Unthinking focus on placebo controls</strong>. It would have been progress to find <strong>anything </strong>that slows ALS. Anything includes placebos. Placebos vary. From the standpoint of those with ALS, it would have been better to compare lithium to nothing than to some sort of placebo. As far as I can tell from the article, no med school professor realized this. No doubt someone has said that the world can be divided into people focused on process (on doing things a certain &#8220;right&#8221; way) and those focused on results (on outcomes). It should horrify all of us that med school professors appear focused on process.</p>
<p>2. <strong>Use of standard statistics (e.g., mean) to measure drug effects</strong>. I have not seen the ALS studies, but if they are like all other clinical trials I&#8217;ve seen, they tested for an effect by comparing means using a parametric test (e.g., a t test). However, effects of treatment are unlikely to have normal distributions nor are likely to be the same for each person. The usual tests are most sensitive when each member of the treatment group improves the same amount and the underlying variation is normally distributed. If 95% of the treatment group is unaffected and 5% show improvement, for example, the usual tests wouldn&#8217;t do the best job of noticing this. If medicine A helps 5% of patients, that&#8217;s an important improvement over 0%, especially with a fatal disease. And if you take it and it doesn&#8217;t help, you stop taking it and look elsewhere. So it would be a good idea to find drugs that only help a fraction of patients, perhaps a small fraction. The usual analyses may have caused drugs that help a small fraction of patients to be considered worthless when they could have been detected.</p>
<p>All the tests of lithium, including the PatientsLikeMe test, turned out negative. The PatientsLikeMe trial didn&#8217;t worry about placebo effects, so my point #1 isn&#8217;t a problem. However, my point #2 probably applies to all four trials.</p>
<p>Thanks to JR Minkel and Melissa Francis.</p>
]]></content:encoded>
			<wfw:commentRss>http://blog.sethroberts.net/2010/07/09/does-lithium-slow-als/feed/</wfw:commentRss>
		<slash:comments>10</slash:comments>
		</item>
		<item>
		<title>Unlikely Data</title>
		<link>http://blog.sethroberts.net/2010/07/08/unlikely-data/</link>
		<comments>http://blog.sethroberts.net/2010/07/08/unlikely-data/#comments</comments>
		<pubDate>Thu, 08 Jul 2010 12:58:54 +0000</pubDate>
		<dc:creator><![CDATA[]]></dc:creator>
				<category><![CDATA[academic fraud]]></category>
		<category><![CDATA[statistics]]></category>

		<guid isPermaLink="false">http://www.blog.sethroberts.net/2010/07/08/unlikely-data/</guid>
		<description><![CDATA[Connoisseurs of scientific fraud may enjoy David Grann&#8217;s terrific article about an art authenticator in the current New Yorker and this post about polling irregularities. What are the odds that two such articles would appear at almost the same time? I suppose I&#8217;m an expert, having published several papers about data that was too unlikely. [&#8230;]]]></description>
				<content:encoded><![CDATA[<p>Connoisseurs of scientific fraud may enjoy <a href="http://www.newyorker.com/reporting/2010/07/12/100712fa_fact_grann">David Grann&#8217;s terrific article about an art authenticator in the current <em>New Yorker</em></a> and <a href="http://www.dailykos.com/story/2010/6/29/169/32552">this post about polling irregularities</a>. What are the odds that two such articles would appear at almost the same time?</p>
<p>I suppose I&#8217;m an expert, having published several papers about data that was too unlikely. With Saul Sternberg and Kenneth Carpenter, I&#8217;ve written about <a href="http://www.sethroberts.net/chandra/index.html">problems with Ranjit Chandra&#8217;s work</a>. I also wrote about <a href="http://sethroberts.net/about/1987_Less_Than_Expected_Variability_in_Evidence.pdf">problems with some learning experiments</a>.</p>
]]></content:encoded>
			<wfw:commentRss>http://blog.sethroberts.net/2010/07/08/unlikely-data/feed/</wfw:commentRss>
		<slash:comments>2</slash:comments>
		</item>
		<item>
		<title>Beijing Street Vendors: What Color Market?</title>
		<link>http://blog.sethroberts.net/2010/06/09/beijing-street-vendors-what-color-market/</link>
		<comments>http://blog.sethroberts.net/2010/06/09/beijing-street-vendors-what-color-market/#comments</comments>
		<pubDate>Wed, 09 Jun 2010 21:07:08 +0000</pubDate>
		<dc:creator><![CDATA[]]></dc:creator>
				<category><![CDATA[Beijing]]></category>
		<category><![CDATA[statistics]]></category>

		<guid isPermaLink="false">http://www.blog.sethroberts.net/2010/06/09/beijing-street-vendors-what-color-market/</guid>
		<description><![CDATA[Black market = illegal. Grey market = &#8220;the trade of a commodity through distribution channels . . . unofficial, unauthorized, or unintended.&#8221; In the evening, near the Wudaokou subway station in Beijing (where lots of students live), dozens of street vendors sell paperbacks ($1 each), jewelry, dresses, socks, scarves, electronic accessories, fruit, toys, shoes, cooked [&#8230;]]]></description>
				<content:encoded><![CDATA[<p>Black market = illegal. <a href="http://en.wikipedia.org/wiki/Grey_market">Grey market</a> = &#8220;the trade of a commodity through distribution channels . . . unofficial, unauthorized, or unintended.&#8221;</p>
<p>In the evening, near the Wudaokou subway station in Beijing (where lots of students live), dozens of street vendors sell paperbacks ($1 each), jewelry, dresses, socks, scarves, electronic accessories, fruit, toys, shoes, cooked food, stuffed animals, and many other things. No doubt it&#8217;s illegal. When a police car approaches, they pick up and leave. Once I saw a group of policemen confiscate a woman&#8217;s goods.</p>
<p>What&#8217;s curious is how far vendors move when police approach. Once I saw the vendors on a corner, all 12 of them, each with a cart, move to the middle of the intersection &#8212; the middle of traffic &#8212; where they clustered. At the time I thought the traffic somehow protected them. Now I think they wanted to move back fast when the police car went away. Tonight, like last night, there&#8217;s a police car at that corner, the northeast corner of the intersection. No vendors there. The vendors who&#8217;d usually be there were now at the northwest corner. In other words, if a policeman got out of his car and walked across the street, he&#8217;d encounter all the vendors that he&#8217;d displaced.</p>
]]></content:encoded>
			<wfw:commentRss>http://blog.sethroberts.net/2010/06/09/beijing-street-vendors-what-color-market/feed/</wfw:commentRss>
		<slash:comments>1</slash:comments>
		</item>
		<item>
		<title>Can John Gottman Predict Divorce With Great Accuracy?</title>
		<link>http://blog.sethroberts.net/2010/06/06/can-john-gottman-predict-divorce-with-great-accuracy/</link>
		<comments>http://blog.sethroberts.net/2010/06/06/can-john-gottman-predict-divorce-with-great-accuracy/#comments</comments>
		<pubDate>Sun, 06 Jun 2010 22:29:14 +0000</pubDate>
		<dc:creator><![CDATA[]]></dc:creator>
				<category><![CDATA[scientific method]]></category>
		<category><![CDATA[statistics]]></category>

		<guid isPermaLink="false">http://www.blog.sethroberts.net/2010/06/06/can-john-gottman-predict-divorce-with-great-accuracy/</guid>
		<description><![CDATA[Andrew Gelman blogged about the research of John Gottman, an emeritus professor at the University of Washington, who claimed to be able to predict whether newlyweds would divorce within 5 years with greater than 90% accuracy. These predictions were based on brief interviews near the time of marriage. Andrew agreed with another critic who said [&#8230;]]]></description>
				<content:encoded><![CDATA[<p><a href="http://www.stat.columbia.edu/~cook/movabletype/archives/2010/06/a_wikipedia_whi.html?utm_source=feedburner&#038;utm_medium=feed&#038;utm_campaign=Feed%3A+StatisticalModelingCausalInferenceAndSocialScience+%28Statistical+Modeling%2C+Causal+Inference%2C+and+Social+Science%29">Andrew Gelman blogged</a> about the research of John Gottman, an emeritus professor at the University of Washington, who claimed to be able to predict whether newlyweds would divorce within 5 years with greater than 90% accuracy. These predictions were based on brief interviews near the time of marriage. Andrew agreed with another critic who said these claims were overstated. He modified Gottman&#8217;s Wikipedia page to reflect those criticisms. Andrew&#8217;s modifications were removed by someone who works for the Gottman Institute.</p>
<p>Were the criticisms right or wrong? The person who removed reference to them in Wikipedia referred to <a href="http://www.gottman.com/49853/Research-FAQs.html">a FAQ page on the Gottman Institute site</a>. Supposedly they&#8217;d been answered there. The criticism is that the &#8220;predictions&#8221; weren&#8217;t predictions: they were descriptions of how closely a model fitted <strong>after </strong>the data were collected could fit the data. If the model were complicated enough (had enough adjustable parameters), it could fit the data perfectly, but that would be no support for the model &#8212; and not &#8220;100% accurate prediction&#8221; as most people understand it.</p>
<p>The FAQ page says this:</p>
<blockquote><p>Six of the seven studies have been predictiveâ€”each began with a  hypothesis about factors leading to divorce. [I think the meaning is this: The first study figured out how to predict. The later six tested that method.] Based on these factors, Dr.  Gottman predicted who would divorce, then followed the couples for a  pre-determined length of time. Finally, he drew conclusions about the  accuracy of his predictions. . . . This is  true prediction.</p>
</blockquote>
<p>This is changing the subject. The question is not whether Gottman&#8217;s research is any help at all, which is the question answered here; the question is whether he can predict at extremely high levels (> 90% accuracy), as claimed. Do the later six studies provide reasonable estimates of prediction accuracy? Presumably the latest ones are better than the earlier ones. The latest one (2002) was obviously not about accurate prediction estimates (its title used the term &#8220;exploratory&#8221;) so I looked at the next newest, published in 2000. Here&#8217;s what <a href="http://psycnet.apa.org/journals/fam/14/1/42/">its abstract</a> says:</p>
<blockquote><p>A longitudinal study with 95 newlywed couples examined the power of the  Oral History Interview to predict stable marital relationships and  divorce. A principal components analysis of the interview with the  couples (Time 1) identified a latent variable, perceived marital bond,  that was significant in predicting which couples would remain married or  divorce within the first 5 years of their marriage. A discriminant  function analysis of the newlywed oral history data predicted, with  87.4% accuracy, those couples whose marriages remained intact or broke  up at the Time 2 data collection point.</p>
</blockquote>
<p>The critics were right. To say a discriminant function &#8220;predicted&#8221; something is to mislead those who don&#8217;t know what a discriminant function is. They don&#8217;t predict, they fit a model to data, after the fact. To call this &#8220;true prediction&#8221; is false.</p>
<p>To me, the &#8220;87.4%&#8221; suggests something seriously off. It is too precise; I would have written &#8220;about 90%&#8221;. It is as if you asked someone their age and they said they were &#8220;24.37 years old.&#8221;</p>
<p>Speaking of overstating your results, <a href="http://www.trialsjournal.com/content/11/1/37">reporting bias in medical research</a>. Thanks to Anne Weiss.</p>
]]></content:encoded>
			<wfw:commentRss>http://blog.sethroberts.net/2010/06/06/can-john-gottman-predict-divorce-with-great-accuracy/feed/</wfw:commentRss>
		<slash:comments>0</slash:comments>
		</item>
		<item>
		<title>Andrew Gelman&#8217;s Top Statistical Tip</title>
		<link>http://blog.sethroberts.net/2010/03/30/andrew-gelmans-top-statistical-tip/</link>
		<comments>http://blog.sethroberts.net/2010/03/30/andrew-gelmans-top-statistical-tip/#comments</comments>
		<pubDate>Tue, 30 Mar 2010 13:04:37 +0000</pubDate>
		<dc:creator><![CDATA[]]></dc:creator>
				<category><![CDATA[data analysis]]></category>
		<category><![CDATA[Modern Veblen]]></category>
		<category><![CDATA[statistics]]></category>

		<guid isPermaLink="false">http://www.blog.sethroberts.net/2010/03/30/andrew-gelmans-top-statistical-tip/</guid>
		<description><![CDATA[Andrew Gelman writes: If I had to come up with one statistical tip that would be most useful to you&#8211;that is, good advice that&#8217;s easy to apply and which you might not already know&#8211;it would be to use transformations. Log, square-root, etc.&#8211;yes, all that, but more! I&#8217;m talking about transforming a continuous variable into several [&#8230;]]]></description>
				<content:encoded><![CDATA[<p>Andrew Gelman <a href="http://www.stat.columbia.edu/~cook/movabletype/archives/2010/03/the_single_most.html">writes</a>:</p>
<blockquote><p>If I had to come up with one statistical tip that would be most useful  to you&#8211;that is, good advice that&#8217;s easy to apply and which you might  not already know&#8211;it would be to use transformations.  Log, square-root,  etc.&#8211;yes, all that, but more!  I&#8217;m talking about transforming a  continuous variable into several discrete variables (to model nonlinear  patterns such as voting by age) and combining several discrete variables  to make something [more] continuous (those &#8220;total scores&#8221; that we all love).   And <em>not</em> doing dumb transformations such as the use of a  threshold to break up a perfectly useful continuous variable into  something binary.  I don&#8217;t care if the threshold is &#8220;clinically  relevant&#8221; or whatever&#8211;just don&#8217;t do it.  If you gotta discretize, for  Christ&#8217;s sake break the variable into <a href="http://www.stat.columbia.edu/%7Egelman/research/published/thirds5.pdf">3  categories</a>.</p></blockquote>
<p>I agree (and wrote <a href="http://sethroberts.net/articles/2008%20Transform%20your%20data.pdf">an article about it</a>). Transforming data is so important that intro stats texts should have a whole chapter on it &#8212; but instead barely mention it. A good discussion of transformation would also include use of principal components to boil down many variables into a much smaller number. (You should do this twice &#8212; once with your independent variables, once with your dependent variables.) Many researchers measure many things (e.g., a questionnaire with 50 questions, a blood test that measures 10 components) and then foolishly correlate all independent variables with all dependent variables. They end up testing dozens of likely-to-be-zero correlations for significance. Thereby effectively throwing all their data away &#8212; when you do dozens of such tests, none can be trusted.</p>
<p>My explanation why this isn&#8217;t taught differs from Andrew&#8217;s. I think it&#8217;s pure Veblen: professors dislike appearing useful and like showing off. Statistics professors, like engineering professors, do less useful research than you might expect, so they are less aware than you might expect of how useful transformations are. And because most transformations don&#8217;t involve esoteric math, writing about them doesn&#8217;t allow you to show off.</p>
<p>In my experience, not transforming your data is at least as bad as throwing half of it away, in the sense that your tests will be that much less sensitive.</p>
]]></content:encoded>
			<wfw:commentRss>http://blog.sethroberts.net/2010/03/30/andrew-gelmans-top-statistical-tip/feed/</wfw:commentRss>
		<slash:comments>4</slash:comments>
		</item>
		<item>
		<title>Exploratory Versus Confirmatory Data Analysis?</title>
		<link>http://blog.sethroberts.net/2010/02/15/exploratory-versus-confirmatory-data-analysis/</link>
		<comments>http://blog.sethroberts.net/2010/02/15/exploratory-versus-confirmatory-data-analysis/#comments</comments>
		<pubDate>Mon, 15 Feb 2010 13:02:15 +0000</pubDate>
		<dc:creator><![CDATA[]]></dc:creator>
				<category><![CDATA[Modern Veblen]]></category>
		<category><![CDATA[self-experimentation]]></category>
		<category><![CDATA[statistics]]></category>

		<guid isPermaLink="false">http://www.blog.sethroberts.net/2010/02/15/exploratory-versus-confirmatory-data-analysis/</guid>
		<description><![CDATA[In 1977, John Tukey published a book called Exploratory Data Analysis. It introduced many new ways of analyzing data, all relatively simple. Most of the new ways involved plotting your data. A few involved transforming your data. Tukey&#8217;s broad point was that statisticians (taught by statistics professors) were missing a lot: Conventional statistics focussed too [&#8230;]]]></description>
				<content:encoded><![CDATA[<p>In 1977, John Tukey published a book called <em>Exploratory Data Analysis</em>. It introduced many new ways of analyzing data, all relatively simple. Most of the new ways involved plotting your data. A few involved transforming your data. Tukey&#8217;s broad point was that statisticians (taught by statistics professors) were missing a lot: Conventional statistics focussed too much on confirmatory data analysis (testing hypotheses) to the omission of exploratory data analysis &#8212; data analysis that might show you something new. <em>Here are some tools to help you explore your data</em>, Tukey was saying.</p>
<p>No question the new tools are useful. I have found great benefits from <a href="http://sethroberts.net/articles/2009%20Plot%20your%20data.pdf">plotting</a> and <a href="http://sethroberts.net/articles/2008%20Transform%20your%20data.pdf">transforming</a> my data. No question that conventional statistics textbooks place far too little emphasis on graphs and transformations. But I no longer agree with Tukey&#8217;s exploratory versus confirmatory distinction. The distinction that matters &#8212; at least to historians, if not to data analysts &#8212; is between low-status and high-status. A more accurate title of Tukey&#8217;s book would have been <em>Low-Status Data Analysis</em>. Exploratory data analysis already had a derogatory name: <em>Descriptive </em>data analysis. As in <em>mere description</em>. Graphs and transformations are low-status. They are low-status because graphs are common and transformations are easy. Anyone can make a graph or transform their data. I believe they were neglected for that reason. To show their high status, statistics professors focused their research and teaching on more difficult and esoteric stuff &#8212; like complicated regression. That the new stuff wasn&#8217;t terribly useful (compared to graphs and transformations) mattered little. Like all academics &#8212; like everyone &#8212; they cared enormously about showing high status. It was far more important to be impressive than to be useful. As Veblen showed, it might have <strong>helped </strong>that the new stuff wasn&#8217;t very useful. &#8220;Applied&#8221; science is lower status than &#8220;pure&#8221; science.</p>
<p>That most of what statistics professors have developed (and taught) is less useful than graphs and transformations strikes me as utterly clear. My explanation is that in statistics, just as in every other academic area I know about, desire to display status led to a lot of useless highly-visible work. (What Veblen called <em>conspicuous waste</em>.) Less visibly, it led to the best tools being neglected. Tukey saw the neglect &#8211;Â  underdevelopment and underteaching of graphs, for example &#8212; but perhaps misdiagnosed the cause. Here&#8217;s why Tukey&#8217;s exploratory versus confirmatory distinction was misleading: Because the tools that Tukey promoted for exploration also improve confirmation. They are neglected everywhere. For example:</p>
<p>1. Graphs improve confirmatory data analysis. If you do a <em>t </em>test (or compute a <em>p </em>value in any way) but don&#8217;t make an associated graph, there is room for improvement. A graph will show whether the assumptions of the computation are reasonable. Often they aren&#8217;t.</p>
<p>2. Transformations improve confirmatory data analysis. That a good transformation will make the assumptions of the test more reasonable many people know. What few people seem to know is that <a href="http://sethroberts.net/about/2005_Three_Things_Statistics_Textbooks_Don%27t_Tell_You%20_Dec_2005.pdf">a good transformation will make the statistical test more sensitive</a>. If a difference exists, the test will be more likely to detect it. This is like increasing your sample size at no extra cost.</p>
<p>3. Exploratory data analysis is sometimes thought of as going beyond the question you started with to find other structure in the data &#8212; to explore your data. (Tukey saw it this way.) But to answer the question you started with as well as possible you should find all the structure in the data. Suppose my question is whether X has an effect.Â  I should care whether Y and Z have an effect in order to (a) make my test of X more sensitive (by removing the effects of Y and Z) and (b) assess the generality of the effect of X (does it interact with Y or Z?).</p>
<p>Most statistics professors and their textbooks have neglected <strong>all</strong> uses of graphs and transformations, not just their exploratory uses. I used to think exploratory data analysis (and exploratory science more generally) needed different tools than confirmatory data analysis and confirmatory science. Now I don&#8217;t. A big simplification.</p>
<p>Exploration (generating new ideas) and confirmation (testing old ideas) are <strong>outputs </strong>of data analysis, not inputs. To explore your data and to test ideas you already have you should do <strong>exactly the same analysis</strong>. What&#8217;s good for one is good for the other.</p>
<p>Likewise, <em>Freakonomics</em> could have been titled <em>Low-status Economics</em>. That&#8217;s essentially what it was, the common theme. Levitt studied all sorts of things other economists thought were beneath them to study. That was Levitt&#8217;s real innovation &#8212; showing that these questions were neglected. Unsurprisingly, the general public, uninterested in the status of economists, found the work more interesting than high-status economics. I&#8217;m sensitive to this because my self-experimentation was extremely low-status. It was useful (low-status), cheap (low-status), small (low-status), and anyone could do it (extremely low status).</p>
<p><strong>More </strong><a href="http://www.stat.columbia.edu/~cook/movabletype/archives/2010/02/exploratory_and.html">Andrew Gelman comments</a>. <a href="http://www.overcomingbias.com/2010/02/function-of-stat-academia.html">Robin Hanson comments</a>.</p>
]]></content:encoded>
			<wfw:commentRss>http://blog.sethroberts.net/2010/02/15/exploratory-versus-confirmatory-data-analysis/feed/</wfw:commentRss>
		<slash:comments>34</slash:comments>
		</item>
		<item>
		<title>Assorted Links</title>
		<link>http://blog.sethroberts.net/2010/02/02/assorted-links-38/</link>
		<comments>http://blog.sethroberts.net/2010/02/02/assorted-links-38/#comments</comments>
		<pubDate>Wed, 03 Feb 2010 02:09:28 +0000</pubDate>
		<dc:creator><![CDATA[]]></dc:creator>
				<category><![CDATA[academic fraud]]></category>
		<category><![CDATA[Assorted Links]]></category>
		<category><![CDATA[books]]></category>
		<category><![CDATA[education]]></category>
		<category><![CDATA[statistics]]></category>

		<guid isPermaLink="false">http://www.blog.sethroberts.net/2010/02/02/assorted-links-38/</guid>
		<description><![CDATA[how Andrew Gelman chooses book titles how to buy a car horizontal evolution was very important The rise of Chinese universities. The world&#8217;s top 100 universities. In 2004, Berkeley was #2 on this list. It is now #39. The IPCC under siege Thanks to Aaron Blaisdell, Tim Beneke, and Stephen Marsh.]]></description>
				<content:encoded><![CDATA[<ul>
<li><a href="http://feedproxy.google.com/~r/StatisticalModelingCausalInferenceAndSocialScience/~3/_mIMcxbFUTM/book_titles.html">how Andrew Gelman chooses book titles</a></li>
<li><a href="http://www.irishtimes.com/newspaper/motors/2009/1028/1224257549944.html">how to buy a car</a></li>
<li><a href="http://www.newscientist.com/article/mg20527441.500-horizontal-and-vertical-the-evolution-of-evolution.html?full=true">horizontal evolution</a> was very important</li>
<li><a href="http://www.guardian.co.uk/education/2010/feb/02/chinese-universities-will-rival-oxbridge">The rise of Chinese universities</a>. <a href="http://www.guardian.co.uk/education/datablog/2009/oct/08/top-100-universities-world">The world&#8217;s top 100 universities</a>. In 2004, Berkeley was #2 on this list. It is now #39.</li>
<li><a href="http://volokh.com/2010/01/31/the-ipcc-under-siege/">The IPCC under siege</a></li>
</ul>
<p>Thanks to Aaron Blaisdell, Tim Beneke, and Stephen Marsh.</p>
]]></content:encoded>
			<wfw:commentRss>http://blog.sethroberts.net/2010/02/02/assorted-links-38/feed/</wfw:commentRss>
		<slash:comments>2</slash:comments>
		</item>
		<item>
		<title>How Much Should We Trust Clinical Trials?</title>
		<link>http://blog.sethroberts.net/2009/07/02/how-much-should-we-trust-clinical-trials/</link>
		<comments>http://blog.sethroberts.net/2009/07/02/how-much-should-we-trust-clinical-trials/#comments</comments>
		<pubDate>Fri, 03 Jul 2009 03:32:18 +0000</pubDate>
		<dc:creator><![CDATA[]]></dc:creator>
				<category><![CDATA[scientific method]]></category>
		<category><![CDATA[statistics]]></category>

		<guid isPermaLink="false">http://www.blog.sethroberts.net/2009/07/02/how-much-should-we-trust-clinical-trials/</guid>
		<description><![CDATA[Suppose you ask several experts how to choose a good car. Their answers reveal they don&#8217;t know how to drive. What should you conclude? Suppose these experts build cars. Should we trust the cars they&#8217;ve built? Gina Kolata writes that &#8220;experts agree that there are three basic principles that underlie the search for medical truth [&#8230;]]]></description>
				<content:encoded><![CDATA[<p>Suppose you ask several experts how to choose a good car. Their answers reveal they don&#8217;t know how to drive. What should you conclude? Suppose these experts <strong>build </strong>cars. Should we trust the cars they&#8217;ve built?</p>
<p><a href="http://www.michaeljfox.org/newsEvents_parkinsonsInTheNews_article.cfm?ID=400">Gina Kolata writes</a> that &#8220;experts agree that there are three basic principles that underlie the search for medical truth and the use of clinical trials to obtain it.&#8221; Kolata&#8217;s &#8220;three basic principles&#8221; reveal that her experts don&#8217;t understand experimentation.</p>
<p><strong>Principle 1.Â </strong> &#8220;It is important to compare like with like. The groups you are comparing must be the same except for one factor â€” the one you are studying. For example, you should compare beta carotene users with people who are exactly like the beta carotene users except that they donâ€™t take the supplement.&#8221; An expert told her this. This &#8212; careful equation of two groups &#8212; is not how experiments are done. What is done is random assignment, which roughly (but not perfectly) equates the groups on pre-experimental characteristics. A more subtle point is that  the X versus No X design is worse than a design that compares different dosages of X. The latter design makes it less likely that control subjects will get upset because they didn&#8217;t get X and makes the two groups more equal.</p>
<p><strong>Principle 2. </strong>&#8220;The bigger the group studied, the more reliable the conclusions.&#8221; Again, this is not what happens. No one with statistical understanding judges the reliability of an effect by the size of the experiment; they judge it by the <em>p</em> value (which takes account of sample size). The more subtle point is that the <strong>smaller </strong>the sample size, the stronger the effect must be to get reliable results. Researchers try to conserve resources so they try to keep experiments as small as possible. Small experiments with reliable results are more impressive than large experiments with equally reliable results &#8212; because the effect must be stronger. This is basically the opposite of what Kolata says.</p>
<p><strong>Principle 3. </strong>In the words of Kolata&#8217;s expert, it&#8217;s &#8220;Bayes theorem&#8221;. He means consider other evidence &#8212; evidence from other studies. This is not only banal, it is meaningless. It is unclear &#8212; at least from what Kolata writes &#8212; how to weigh the various sources of evidences (what if the other evidence and the clinical trials disagree?).</p>
<p>Kolata also quotes David Freedman, <a href="http://www.blog.sethroberts.net/2008/12/02/unfortunate-obituaries-the-case-of-david-freedman/">a Berkeley professor of statistics who knew the cost of everything and the value of nothing</a>. Perhaps it starts in medical school. As I blogged, <a href="http://www.blog.sethroberts.net/2006/09/22/seymour-benzer-crippling-med-school-research/">working scientists, who have a clue, don&#8217;t want to teach medical students</a> how to do research.</p>
<p>If this is the level of understanding of the people who do clinical trials, how much should we trust them? Presumably Kolata&#8217;s experts were better than average &#8212; a scary thought.</p>
]]></content:encoded>
			<wfw:commentRss>http://blog.sethroberts.net/2009/07/02/how-much-should-we-trust-clinical-trials/feed/</wfw:commentRss>
		<slash:comments>12</slash:comments>
		</item>
		<item>
		<title>Will Like vs. Might Love vs. Might Hate</title>
		<link>http://blog.sethroberts.net/2009/02/28/will-like-vs-might-like-vs-might-hate/</link>
		<comments>http://blog.sethroberts.net/2009/02/28/will-like-vs-might-like-vs-might-hate/#comments</comments>
		<pubDate>Sun, 01 Mar 2009 04:54:25 +0000</pubDate>
		<dc:creator><![CDATA[]]></dc:creator>
				<category><![CDATA[ignorance]]></category>
		<category><![CDATA[scientific method]]></category>
		<category><![CDATA[self-experimentation]]></category>
		<category><![CDATA[statistics]]></category>
		<category><![CDATA[toxicology]]></category>

		<guid isPermaLink="false">http://www.blog.sethroberts.net/2009/02/28/will-like-vs-might-like-vs-might-hate/</guid>
		<description><![CDATA[What to watch? Entertainment Weekly has a feature called Critical Mass: Ratings of 7 critics are averaged. Those averages are the critical response that most interests me. Rotten Tomatoes also computes averages over critics. It uses a 0-100 scale. In recent months, my favorite movie was Gran Torino, which rated 80 at Rotten Tomatoes (quite [&#8230;]]]></description>
				<content:encoded><![CDATA[<p>What to watch? <em>Entertainment Weekly</em> has a feature called <a href="http://www.ew.com/ew/news/charts/movies/criticalmass/0,,,00.html">Critical Mass</a>: Ratings of 7 critics are averaged. Those averages are the critical response that most interests me. <a href="http://www.rottentomatoes.com/">Rotten Tomatoes</a> also computes averages over critics. It uses a 0-100 scale. In recent months, my favorite movie was <em>Gran Torino</em>, which rated 80 at Rotten Tomatoes (quite good). <em>Slumdog Millionaire</em>, which I also liked, got a 94 (very high).</p>
<p>Is an average the best way to summarize several reviews? People vary a lot in their likes and dislikes &#8212; what if I&#8217;m looking for a movie I <em>might </em>like a lot? Then the maximum (best) review might be a better summary measure; if the maximum is high, it means that someone liked the movie a lot. A score of 94 means that almost every critic liked <em>Slumdog Millionaire</em>, but the more common score of 80 is ambiguous: Were most critics a bit lukewarm or was wild enthusiasm mixed with dislike? Given that we have an enormous choice of movies &#8212; especially on<em> </em>Rotten Tomatoes<em> </em>&#8211; I might want to find five movies that <em>someone </em>was wildly enthusiastic about and read their reviews. Movies that everyone likes (e.g., 94 rating) are rare.</p>
<p>Another possibility is that I&#8217;m going to the movies with several friends and I just want to make sure no one is going to hate the chosen movie. Then I&#8217;d probably want to see the <em>minimum </em>ratings, not the average ratings.</p>
<p>So: different questions, wildly different &#8220;averages&#8221;. I have never heard a statistician or textbook make this point except trivially (if you want the &#8220;middle&#8221; number choose the median, a textbook might say).Â  The possibility of &#8220;averages&#8221; wildly different from the mean or median is important because averaging is at the heart of how medical and other health treatments are evaluated. The standard evaluation method in this domain is to compare the mean of two groups &#8212; one treated, one untreated (or perhaps the two groups get two different treatments).</p>
<p>If there is time to administer only one treatment, then we probably do want the treatment most likely to help. But if there are many treatments available and there is time to administer more than one treatment &#8212; if the first one fails, try another, and so on &#8212; then it is not nearly so obvious that we want the treatment with the best mean score. Given big differences from person to person, we might want to know what treatments worked really well with <em>someone</em>. Conversely, if we are studying side effects, we might want to know which of two treatments was more likely to have extremely bad outcomes. We would certainly prefer a summary like the minimum (worst) to a summary like the median or mean.</p>
<p>Outside of emergency rooms, there is usually both a wide range of treatment choice and plenty of time to try more than one. For example, you want to lower your blood pressure. This is why medical experts who deride &#8220;anecdotal evidence&#8221; are like people trying to speak a language they don&#8217;t know &#8212; and don&#8217;t realize they don&#8217;t know. (Their cluelessness is enshrined in a saying: <a href="http://www.chrisjohnsonmd.com/blog/2008/11/30/how-to-use-medical-evidence-iii-case-reports-and-descriptive-series/"><em>the plural of anecdote is not data</em></a>.) In such situations, extreme outcomes, even if rare, become far more important than averages. You want to avoid the extremely bad (even if rare) outcomes, such as <a href="http://www.washingtonpost.com/wp-dyn/content/article/2006/12/13/AR2006121300452.html">antidepressants that cause suicide</a>. And if a small fraction of people respond extremely well to a treatment that leaves most people unchanged, you want to know that, too. Non-experts grasp this, I think. This is why they are legitimately interested in anecdotal evidence, which does a better job than means or medians of highlighting extremes. It is the medical experts, who have read the textbooks but fail to understand their limitations, whose understanding has considerable room for improvement.</p>
]]></content:encoded>
			<wfw:commentRss>http://blog.sethroberts.net/2009/02/28/will-like-vs-might-like-vs-might-hate/feed/</wfw:commentRss>
		<slash:comments>3</slash:comments>
		</item>
	</channel>
</rss>

<!-- Performance optimized by W3 Total Cache. Learn more: http://www.w3-edge.com/wordpress-plugins/

Content Delivery Network via Amazon Web Services: S3: srblogfiles.s3.amazonaws.com

 Served from: blog.sethroberts.net @ 2014-10-12 22:55:05 by W3 Total Cache -->